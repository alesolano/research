# Ale Solano's Research

## Motivation

This repository is motivated by Ali Rahimi's talk on NIPS 2017, warning about how machine learning research today resembles more alchemy than science. I'm not part of the research community so I can't say if it's a legit affirmation or not, but I'm not going to deny that I have that perception sometimes, though I'm sure it's not completely that way.

Deep Learning may seem at first sight as some sort of this new toy humans have discovered and are just using in a lot of situations to reveal all its power. It seems that we are observing succesful results before fully understanding the theory behind them. This is clearly opposed to my perception of the robotics research field, in which I feel we have needed first a very strong theoretical background before enjoying the first succeses. The ratio between behaviors accomplished and behaviors previously studied seems closer to 1:1.

## Goals

The primary goal of this repository is to understand, rigorously, every detail in deep learning. I will apply the famous quote of Richard Feynman, _"What I cannot create, I do not understant"_, building every deep neural network to observe its strengths and flaws and understand researchers' decisions when it comes to design their models. Loss functions, optimizers, batch normalization, activation functions... where do they come from, theoretically? What are their contribution in a network performance, empirically? Why does it happen that way? In essence, get to know all the parameters in a neural network architecture and the implications of altering each one of them. As Ali Rahimi said, apply **reductionism** to deep learning.

The ultimate goal is to be able to **participate in the conversation** that it's taking place in the deep learning research community. Every couple of months there is a major conference where astounding results appear and are discussed: I want to be familiar with them, so one day I can add some discoveries and help the community. Research is essentially asking questions and, hopefully, solve them; but, if you can't even ask relevant questions, there is no way you can contribute to the field.

## Structure

I'll be focusing on deep learning for computer vision that could eventually be applied to roboticsThere will be a folder for everything related to deep learning.

Along the way, I'll also learn about probability, robotics, control theory, algorithms, hardware, so I will add more folders to the repository. This won't only cover things that I'm learning right now: I have a background in robotics (navigation for mobile robots and control for manipulators), but I will also try to apply reductionism to all I already know in order to build upon concepts that I fully understand.

I'll use Jupyter Notebooks since they are pretty good for building things you don't understand at first, and also allows you to include markdown text and picture, that may help a lot in my understanding. Bad news is that, today, Jupyter Notebook suck at version control. As Jupyter is an open source tool, I'm going to take that as a responsibility too. I hope I can help the community to improve the concept of notebooks. I feel like the future of research papers are close to what notebooks offer, though it's not perfected.